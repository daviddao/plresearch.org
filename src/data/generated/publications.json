[{"slug":"goren2024","title":"A finality calculator for Filecoin’s Expected Consensus","date":"2024-02-01T00:00:00.000Z","authors":["guy-goren","jorge-soares"],"venue":"","doi":"","publication_types":["report"],"areas":["distributed-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>We propose a finality calculator for Filecoin’s Expected consensus that considers what takes place during epochs and can\nattain, under normal operating conditions, an error probability of 2^(−30) in 30 epochs (15 minutes) - a 30x improvement\nover the current 900-epoch threshold. It depends only on a node’s local view and can be implemented without protocol\nchanges.</p>\n"},{"slug":"giacomelli2023","title":"Filecoin Proof of Useful Space","date":"2023-08-30T00:00:00.000Z","authors":["irene-giacomelli","luca-nizzardo"],"venue":"","doi":"","publication_types":["report"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"","html":"<p>This document provides a simple formal definition of Proof of Space (taken from the academic literature) and an informal definition of persistent and useful space (needed for Filecoin). It describes construction details and a security proof for the Stacked-DRGs proof of space (SDR), and goes into how SDR is used in Filecoin. In particular, it includes a description and analysis for Filecoin's PoRep, WindowPoSt and WinningPoSt.</p>\n"},{"slug":"wang2023","title":"Security analysis of Filecoin's Expected Consensus in the Byzantine vs honest model","date":"2023-08-14T00:00:00.000Z","authors":["xuechao-wang","sarah-azouvi","marko-vukolic"],"venue":"AFT 2023","doi":"","publication_types":["conference-paper"],"areas":["distributed-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Filecoin is the largest storage-based open-source blockchain, both by storage capacity (>11EiB) and market capitalization. This paper provides the first formal security analysis of Filecoin's consensus (ordering) protocol, Expected Consensus (EC). Specifically, we show that EC is secure against an arbitrary adversary that controls a fraction β of the total storage for βm&#x3C;1−e−(1−β)m, where m is a parameter that corresponds to the expected number of blocks per round, currently m=5 in Filecoin. We then present an attack, the n-split attack, where an adversary splits the honest miners between multiple chains, and show that it is successful for βm≥1−e−(1−β)m, thus proving that βm=1−e−(1−β)m is the tight security threshold of EC. This corresponds roughly to an adversary with 20% of the total storage pledged to the chain. Finally, we propose two improvements to EC security that would increase this threshold. One of these two fixes is being implemented as a Filecoin Improvement Proposal (FIP).</p>\n"},{"slug":"azouvi2023","title":"Base fee manipulation in Ethereum's EIP-1559 transaction fee mechanism","date":"2023-04-22T00:00:00.000Z","authors":["sarah-azouvi","guy-goren","Lioba Heimbach","Alexander Hicks"],"venue":"DISC 2023","doi":"","publication_types":["conference-paper"],"areas":["distributed-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>In 2021 Ethereum adjusted the transaction pricing mechanism by implementing EIP-1559, which introduces the base fee - a fixed network fee per block that is burned and adjusted dynamically in accordance with network demand. The authors of the Ethereum Improvement Proposal (EIP) noted that a miner with more than 50% of the mining power might have an incentive to deviate from the honest mining strategy. Instead, such a miner could propose a series of empty blocks to increase its future rewards. In this paper, we generalize this attack and show that under rational player behavior, deviating from the honest strategy can be profitable for a miner with less than 50% of the mining power. Further, even when miners do not collaborate, it is rational for smaller mining power miners to join the attack.</p>\n"},{"slug":"winetraub2023","title":"SpaceVDF: Verifiable delay functions using cryptographic satellites","date":"2023-03-21T00:00:00.000Z","authors":["Yonatan Winetraub","Elad Sagi","Yan Michalevsky","chhimed-kunzang","jonathan-gross"],"venue":"","doi":"","publication_types":["report"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"","html":"<p>In this document we aim to evaluate how VDF algorithms based on physical limits can be implemented in satellites and which physical properties / or roles of physics we can utilize to guarantee the passage of time. The goal of this study is to perform principal system analysis, identify main issues and risks, propose a path for derisking and come up with a budget and timeline for a suitable satellite (or satellite constellation).</p>\n"},{"slug":"amin2023","title":"LURK: Lambda, the ultimate recursive knowledge","date":"2023-03-16T00:00:00.000Z","authors":["Nada Amin","John Burnham","François Garillot","rosario-gennaro","chhimed-kunzang","Daniel Rogozin","Cameron Wong"],"venue":"","doi":"","publication_types":["report"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"https://eprint.iacr.org/2023/369","html":"<p>We introduce Lurk, a new LISP-based programming language for zk-SNARKs. Traditional approaches to programming over zero-knowledge proofs require compiling the desired computation into a flat circuit, imposing serious constraints on the size and complexity of computations that can be achieved in practice. Lurk programs are instead provided as data to the universal Lurk interpreter circuit, allowing the resulting language to be Turing-complete without compromising the size of the resulting proof artifacts. Our work describes the design and theory behind Lurk, along with detailing how its implementation of content addressing can be used to sidestep many of the usual concerns of programming zero-knowledge proofs.</p>\n"},{"slug":"gailly2023","title":"tlock: Practical timelock encryption from threshold BLS","date":"2023-02-13T00:00:00.000Z","authors":["nicolas-gailly","Kelsey Melissaris","yolan-romailler"],"venue":"","doi":"","publication_types":["report"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"","html":"<p>We present a practical construction and implementation of timelock encryption, in which a ciphertext is guaranteed to be decryptable only after some specified time has passed. We employ an existing threshold network, the League of Entropy, implementing threshold BLS [BLS01, B03] in the context of Boneh and Franklin's identity-based encryption (IBE). At present this threshold network broadcasts BLS signatures over each round number, equivalent to the current time interval, and as such can be considered a decentralised key holder periodically publishing private keys for the IBE where identities are the round numbers. A noticeable advantage of this scheme is that only the encryptors and decryptors are required to perform any additional cryptographic operations; the threshold network can remain unaware of the TLE and does not have to change to support the scheme. We also release an open-source implementation of our scheme and a live web page that can be used in production now relying on the existing League of Entropy network acting as a distributed public randomness beacon service using threshold BLS signatures.</p>\n"},{"slug":"plnetworkgoods2023","title":"Generalized Impact Evaluators","date":"2023-01-10T00:00:00.000Z","authors":[],"venue":"","doi":"","publication_types":["white-paper"],"areas":["distributed-systems","networking"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Existing funding systems fail to sufficiently fund public goods and common goods due to insufficient mechanisms for coordinating various agents towards valuable outcomes. Relative to traditional capital systems that scalably organize activity around maximizing financial performance, impact funding remains underdeveloped, especially in the ability to reward high-upside, high-uncertainty work. Here, we propose Impact Evaluators (IEs) as a modular system for coordinating work by measuring, evaluating, and retrospectively rewarding the impact achieved towards specified valuable objectives. We present a structure to define Impact Evaluators as well as design schematics to facilitate their implementation. We then discuss implementation considerations, practical learnings from past experiments, and integration with the broader ecosystem of public goods and commons funding systems.</p>\n"},{"slug":"azouvi2022b","title":"Pikachu: Securing PoS blockchains from long-range attacks by checkpointing into Bitcoin PoW using Taproot","date":"2022-12-13T00:00:00.000Z","authors":["sarah-azouvi","marko-vukolic"],"venue":"ConsensusDay 22","doi":"10.1145/3560829.3563563","publication_types":["conference-paper"],"areas":["distributed-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Blockchain systems based on a reusable resource, such as proof-of-stake (PoS), provide weaker security guarantees than those based on proof-of-work. Specifically, they are vulnerable to long-range attacks, where an adversary can corrupt prior participants in order to rewrite the full history of the chain. To prevent this attack on a PoS chain, we propose a protocol that checkpoints the state of the PoS chain to a proof-of-work blockchain such as Bitcoin. Our checkpointing protocol hence does not rely on any central authority. Our work uses Schnorr signatures and leverages Bitcoin recent Taproot upgrade, allowing us to create a checkpointing transaction of constant size. We argue for the security of our protocol and present an open-source implementation that was tested on the Bitcoin testnet.</p>\n"},{"slug":"monteiro2022","title":"Enriching Kademlia by partitioning","date":"2022-12-13T00:00:00.000Z","authors":["João Monteiro","Pedro Ákos Costa","João Leitão","alfonso-delarocha","yiannis-psaras"],"venue":"DINPS 22","doi":"","publication_types":["conference-paper"],"areas":["distributed-systems","networking"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Decentralizing the Web is becoming an increasingly interesting endeavor that aims at improving user security and privacy as well as providing guaranteed ownership of content. One such endeavor that pushes towards this reality, is Protocol Labs' Inter-Planetary File System (IPFS) network, that provides a decentralized large scale file system to support the decentralized Web. To achieve this, the IPFS network leverages the Kademlia DHT to route and store pointers to content stored by network members (i.e., peers). However, due to the large number of network peers, content, and accesses, the DHT routing needs to be efficient and quick to enable a decentralized web that is competitive.</p>\n<p>In this paper, we present work in progress that aims at improving the Kademlia DHT performance through the manipulation of DHT identifiers by adding prefixes to identifiers. With this, we are able to bias the DHT topological organization towards locality (which can be either geographical or applicational), which creates partitions in the DHT and enables faster and more efficient query resolution on local content. We designed prototypes that implement our proposal, and performed a first evaluation of our work in an emulated network testbed composed of 5000 nodes. Our results show that our proposal can benefit the DHT look up on data with locality with minimal overhead.</p>\n"},{"slug":"psaras2022","title":"To the InterPlanetary File System – and beyond!: Peer-to-peer file sharing would make the Internet far more efficient","date":"2022-11-07T00:00:00.000Z","authors":["yiannis-psaras","jorge-soares","david-dias"],"venue":"IEEE Spectrum","doi":"10.1109/MSPEC.2022.9941036","publication_types":["journal-article"],"areas":["distributed-systems","networking"],"abstract":"","url_pdf":"","url_source":"","html":"<p>When the COVID-19 pandemic erupted in early 2020, the world made an unprecedented shift to remote work. As a precaution, some Internet providers scaled back service levels temporarily, although that probably wasn't necessary for countries in Asia, Europe, and North America, which were generally able to cope with the surge in demand caused by people teleworking (and binge-watching Netflix). That's because most of their networks were overprovisioned, with more capacity than they usually need. But in countries without the same level of investment in network infrastructure, the picture was less rosy: Internet service providers (ISPs) in South Africa and Venezuela, for instance, reported significant strain.</p>\n"},{"slug":"campanelli2022f","title":"Structure-preserving compilers from new notions of obfuscations","date":"2022-11-01T00:00:00.000Z","authors":["matteo-campanelli","Danilo Francati","Claudio Orlandi"],"venue":"","doi":"","publication_types":["report"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"","html":"<p>The dream of software obfuscation is to take programs, as they are, and then compile them into obfuscated versions that hide their secret inner workings. In this work we investigate notions of obfuscations weaker than virtual black-box (VBB) but which still allow obfuscating\ncryptographic primitives preserving their original functionalities as much as possible. In particular we propose two new notions of obfuscations, which we call oracle-differing-input obfuscation (odiO) and oracle-indistinguishability obfuscation (oiO). In a nutshell, odiO is a natural strengthening of differing-input obfuscation (diO) and allows obfuscating programs for which it is hard to find a differing-input when given only oracle access to the programs. An oiO obfuscator allows to obfuscate programs that are hard to distinguish when treated as oracles.\nWe then show applications of these notions, as well as positive and negative results around them. A few highlights include:\n– Our new notions are weaker than VBB and stronger than diO.\n– As it is the case for VBB, we show that there exist programs that cannot be obfuscated with odiO or oiO.\n– Our new notions allow to compile several flavours of secret key primitives (e.g., SKE, MAC, designated verifier NIZK) into their public key equivalent (e.g., PKE, signatures, publicly verifiable NIZK) while preserving one of the algorithms of the original scheme (function-preserving), or the structure of their outputs (format-preserving).</p>\n"},{"slug":"vukolic2022","title":"Mir-BFT: Scalable and robust BFT for decentralized networks","date":"2022-10-24T00:00:00.000Z","authors":["Chrysoula Stathakopoulou","David Tudor","matej-pavlovic","marko-vukolic"],"venue":"Journal of Systems Research","doi":"10.5070/SR32159278","publication_types":["journal-article"],"areas":["distributed-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>This paper presents Mir-BFT, a robust Byzantine fault-tolerant (BFT) total order broadcast protocol aimed at maximizing throughput on wide-area networks (WANs), targeting deployments in decentralized networks, such as permissioned and Proof-of-Stake permissionless blockchain systems.</p>\n<p>Mir-BFT is the first BFT protocol that allows multiple leaders to propose request batches independently (i.e., parallel leaders), while effectively precluding performance degradation due to request duplication by rotating the assignment of a partitioned request hash space to leaders. As this mechanism removes the single-leader bandwidth bottleneck and exposes a computation bottleneck related to authenticating clients even on a WAN, our protocol further boosts through-put using a client signature verification sharding optimization. Our evaluation shows that Mir-BFT outperforms state-of-the-art single-leader protocols and orders more than 60000 signed Bitcoin-sized (500-byte) transactions per second on a widely distributed setup (100 nodes, 1 Gbps WAN) with typical latencies of few seconds. Moreover, our evaluation exposes the impact of duplicate requests on parallel leader protocols which Mir-BFT eliminates. We also evaluate Mir-BFT un-der different crash and Byzantine faults, demonstrating its performance robustness.</p>\n<p>Mir-BFT relies on classical BFT protocol constructs, which simplifies reasoning about its correctness. Specifically, Mir-BFT is a generalization of the celebrated and scrutinized PBFT protocol. In a nutshell, Mir-BFT follows PBFT “safety-wise”, with changes needed to accommodate novel features restricted to PBFT liveness.</p>\n"},{"slug":"seemann2022","title":"Decentralized hole punching","date":"2022-09-28T00:00:00.000Z","authors":["marten-seemann","Max Inden","Dimitris Vyzovitis"],"venue":"DINPS 2022","doi":"","publication_types":["conference-paper"],"areas":["distributed-systems","networking"],"abstract":"","url_pdf":"","url_source":"","html":"<p>We present a decentralized hole punching mechanism built into the peer-to-peer networking library libp2p. Hole punching is crucial for peer-to-peer networks, enabling each participant to directly communicate to any other participant, despite being separated by firewalls and NATs. The decentralized libp2p hole punching protocol leverages protocols similar to STUN (RFC 8489), TURN (RFC 8566) and ICE (RFC 8445), without the need for any centralized infrastructure. Specifically, it doesn’t require any previous knowledge about network participants other than at least one (any arbitrary) node to bootstrap peer discovery. The key insight is that the protocols used for hole punching, namely address discovery and relaying protocols, can be built such that their resource requirements are negligible. This makes it feasible for any participant in the network to run these, thereby enabling the coordination of hole punch attempts, assuming that at least a small fraction of nodes is not located behind a firewall or a NAT.</p>\n"},{"slug":"campanelli2022e","title":"Impossibilities in succinct arguments: Black-box extraction and more","date":"2022-09-09T00:00:00.000Z","authors":["matteo-campanelli","Chaya Ganesh","Hamidreza Khoshakhlagh","Janno Siim"],"venue":"","doi":"","publication_types":["report"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"","html":"<p>The celebrated result by Gentry and Wichs established a theoretical barrier for succinct non-interactive arguments (SNARGs), showing that for (expressive enough) hard-on-average languages we must assume non-falsifiable assumptions. We further investigate those barriers by showing new negative and positive results related to extractability and to the preprocessing model.</p>\n<ol>\n<li>We first ask the question “are there further barriers to SNARGs that are knowledge-sound (SNARKs) and with a black-box extractor?”. We show it is impossible to have such SNARKs in the standard model. This separates SNARKs in the random oracle model (which can have black-box extraction) and those in the standard model.</li>\n<li>We find positive results regarding the same question in the non-adaptive setting. Under the existence of SNARGs (without extractability) and from standard assumptions, it is possible to build SNARKs with black-box extractability for a non-trivial subset of NP.</li>\n<li>On the other hand, we show that (under some mild assumptions) all NP languages cannot have SNARKs with black-box extractability even in the non-adaptive setting.</li>\n<li>The Gentry-Wichs result does not account for the preprocessing model, under which fall several efficient constructions. We show that also in the preprocessing model it is impossible to construct SNARGs that rely on falsifiable assumptions in a black-box way.\nAlong the way, we identify a class of non-trivial languages, which we dub “trapdoor languages”, that bypass some of these impossibility results.</li>\n</ol>\n"},{"slug":"campanelli2022d","title":"Curve trees: Practical and transparent zero-knowledge accumulators","date":"2022-09-08T00:00:00.000Z","authors":["matteo-campanelli","Mathias Hall-Andersen"],"venue":"","doi":"","publication_types":["report"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"","html":"<p>In this work we propose a new accumulator construction and efficient ways to prove knowledge of some element in a set without leaking anything about the element. This problem arises in several applications including privacy-preserving distributed ledgers (e.g., Zcash) and anonymous credentials. Our approaches do not require a trusted setup and significantly improve on the efficiency state of the of the art.\nWe introduce new techniques inspired by commit-and-prove techniques and combine shallow Merkle trees, 2-cycles of elliptic curves to obtain constructions that are highly practical. Our basic construction—which we dub Curve Trees—is completely transparent (does not require a trusted setup) and is based on simple standard assumptions (DLOG and Random Oracle Model). It has small proofs and commitments and very efficient proving and verification time.\nCurve trees can be instantiated to be efficient in practice: the commitment to a set (accumulator) is 256 bits for any set size; for a set of size 232 a proof is approximately 2KB, a verifier runs in ≈160ms (easily parallelizable to ≈80ms) and a prover in ≈3.6s on an ordinary laptop.\nUsing our construction as a building block we can construct a simple and concretely efficient anonymous cryptocurrency with full anonymity set.\nWe estimate the verification time to be ≈320ms (and trivially parallelizable to run in ≈160ms) or &#x3C;10 ms when batch-verifying multiple (>100) transactions simultaneously. Transaction sizes are &#x3C;3KB. Our timings are competitive with those of the approach in Zcash Sapling and trade slightly larger proofs (proofs in Zcash are 0.2KB) for a completely transparent setup.</p>\n"},{"slug":"campanelli2022c","title":"Encryption to the future: A paradigm for sending secret messages to future (anonymous) committees","date":"2022-08-30T00:00:00.000Z","authors":["matteo-campanelli","Bernardo David","Hamidreza Khoshakhlagh","Anders Konring","Jesper Buus Nielsen"],"venue":"Asiacrypt 2022","doi":"","publication_types":["conference-paper"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"","html":"<p>A number of recent works have constructed cryptographic protocols with flavors of adaptive security by having a randomly-chosen anonymous committee run at each round. Since most of these protocols are stateful, transferring secret states from past committees to future, but still unknown, committees is a crucial challenge. Previous works have tackled this problem with approaches tailor-made for their specific setting, which mostly rely on using a blockchain to orchestrate auxiliary committees that aid in state hand-over process. In this work, we look at this challenge as an important problem on its own and initiate the study of Encryption to the Future (EtF) as a cryptographic primitive. First, we define a notion of a <em>non-interactive</em> EtF scheme where time is determined with respect to an underlying blockchain and a lottery selects parties to receive a secret message at some point in the future. While this notion seems overly restrictive, we establish two important facts: 1. if used to encrypt towards parties selected in the \"far future\", EtF implies witness encryption for NP over a blockchain; 2. if used to encrypt only towards parties selected in the \"near future\", EtF is not only sufficient for transferring state among committees as required by previous works, but also captures previous tailor-made solutions. To corroborate these results, we provide a novel construction of EtF based on witness encryption over commitments (cWE), which we instantiate from a number of standard assumptions via a construction based on generic cryptographic primitives. Finally, we show how to use \"near future\" EtF to obtain \"far future\" EtF with a protocol based on an auxiliary committee whose communication complexity is <em>independent</em> of the length of plaintext messages being sent to the future.</p>\n"},{"slug":"trautwein2022","title":"Design and evaluation of IPFS: A storage layer for the decentralized web","date":"2022-07-26T00:00:00.000Z","authors":["Dennis Trautwein","Aravindh Raman","Gareth Tyson","Ignacio Castro","will-scott","Moritz Schubotz","Bela Gipp","yiannis-psaras"],"venue":"ACM SIGCOMM 2022","doi":"","publication_types":["conference-paper"],"areas":["distributed-systems","networking"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Recent years have witnessed growing consolidation of web operations. For example, the majority of web traffic now originates from a few organizations, and even micro-websites often choose to host on large pre-existing cloud infrastructures. In response to this, the “Decentralized Web” attempts to distribute ownership and operation of web services more evenly. This paper describes the design and implementation of the largest and most widely used Decentralized Web platform — the InterPlanetary File System (IPFS) — an open-source, content-addressable peer-to-peer network that provides distributed data storage and delivery. IPFS has millions of daily content retrievals and already underpins dozens of thirdparty applications. This paper evaluates the performance of IPFS by introducing a set of measurement methodologies that allow us to uncover the characteristics of peers in the IPFS network. We reveal presence in more than 2700 Autonomous Systems and 152 countries, the majority of which operate outside large central cloud providers like Amazon or Azure. We further evaluate IPFS performance, showing that both publication and retrieval delays are acceptable for a wide range of use cases. Finally, we share our datasets, experiences and lessons learned.</p>\n"},{"slug":"campanelli2022b","title":"Linear-map vector commitments and their practical applications","date":"2022-07-06T00:00:00.000Z","authors":["matteo-campanelli","anca-nitulescu","Carla Ràfols","Alexandros Zacharakis","Arantxa Zapico"],"venue":"","doi":"","publication_types":["report"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Vector commitments (VC) are a cryptographic primitive that allow one to commit to a vector and then “open” some of its positions efficiently. Vector commitments are increasingly recognized as a central tool to scale highly decentralized networks of large size and whose content is dynamic. In this work, we examine the demands on the properties that an ideal vector commitment should satisfy in the light of the emerging plethora of practical applications and propose new constructions that improve the state-of-the-art in several dimensions and offer new tradeoffs. We also propose a unifying framework that captures several constructions and show how to generically achieve some properties from more basic ones. On the practical side, we focus on building efficient schemes that do not require new trusted setup (we can reuse existing ceremonies for pairing-based “powers of tau” run by real-world systems such as ZCash or Filecoin). Our (in-progress) implementation demonstrates that our work over-performs in efficiency prior schemes with same properties.</p>\n"},{"slug":"ganesh2022","title":"What makes Fiat–Shamir zkSNARKs (updatable SRS) simulation extractable?","date":"2022-07-06T00:00:00.000Z","authors":["Chaya Ganeshe","Hamidreza Khoshakhlagh","Markulf Kohlweiss","anca-nitulescu","Michal Zajac"],"venue":"SCN 2022","doi":"","publication_types":["conference-paper"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"","html":"<p>We show that three popular universal zero-knowledge SNARKs (Plonk, Sonic, and Marlin) are updatable SRS simulation extractable NIZKs and signatures of knowledge (SoK) out-of-the-box avoiding any compilation overhead.</p>\n<p>Towards this we generalize results for the Fiat--Shamir (FS) transformation, which turns interactive protocols into signature schemes, non-interactive proof systems, or SoK in the random oracle model (ROM).  The security of the transformation relies on rewinding to extract the secret key or the witness, even in the presence of signing queries for signatures and simulation queries for proof systems and SoK, respectively.  We build on this line of work and analyze multi-round FS for arguments with a structured reference string (SRS). The combination of ROM and SRS, while redundant in theory, is the model of choice for the most efficient practical systems to date. We also consider the case where the SRS is updatable and define a strong simulation extractability notion that allows for simulated proofs with respect to an SRS to which the adversary can contribute updates.</p>\n<p>We define three properties (trapdoor-less zero-knowledge, rewinding-based knowledge soundness, and a unique response property) that are sufficient for argument systems based on multi-round FS to be also simulation extractable in this strong sense. We show that Plonk, Sonic, and Marlin satisfy these properties, and conjecture that many other argument systems such as Lunar, Basilisk, and transparent variants of Plonk fall within the reach of our main theorem.</p>\n"},{"slug":"zapico2022","title":"Caulk: Lookup arguments in sublinear time","date":"2022-07-06T00:00:00.000Z","authors":["Arantxa Zapico","Vitalik Buterin","Dmitry Khovratovich","Mary Maller","anca-nitulescu","Mark Simkin"],"venue":"","doi":"","publication_types":["report"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"","html":"<p>We present position-hiding linkability for vector commitment schemes: one can prove in zero knowledge that one or m values that comprise commitment cm all belong to the vector of size N committed to in C. Our construction Caulk can be used for membership proofs and lookup arguments and outperforms all existing alternatives in prover time by orders of magnitude.</p>\n<p>For both single- and multi-membership proofs Caulk beats SNARKed Merkle proofs by the factor of 100 even if the latter instantiated with Poseidon hash. Asymptotically our prover needs O(m^2 + m.log(N)) time to prove a batch of m openings, whereas proof size is O(1) and verifier time is O(log(log(N))).</p>\n<p>As a lookup argument, Caulk is the first scheme with prover time sublinear in the table size, assuming O(N.log(N)) preprocessing time and O(N) storage. It can be used as a subprimitive in verifiable computation schemes in order to drastically decrease the lookup overhead.</p>\n<p>Our scheme comes with a reference implementation and benchmarks.</p>\n"},{"slug":"davis2022","title":"Influencing NFT pricing on secondary markets: A case study of Vpunks","date":"2022-06-15T00:00:00.000Z","authors":["trent-davis"],"venue":"CryptoAssets and Digital Asset Investment Conference","doi":"","publication_types":["conference-paper"],"areas":["cryptoeconomics"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Non-fungible tokens (NFTs) allow for users to transfer the digital rights of a good, for example, art, via a blockchain. This enables users to track the art’s proof of origin and authenticity. We investigate potential influence auction house features, project roadmaps, and community growth have on NFT sales prices. Using OLS techniques and data from 7,272 secondary sales of the NFT project Vpunks we find auction house features, like being able to sort via price or rarity, decrease the sales price. We also find increased community engagement and the existence of a roadmap to increase sales prices.</p>\n"},{"slug":"catalano2022","title":"On the impossibility of algebraic vector commitments in pairing-free groups","date":"2022-06-02T00:00:00.000Z","authors":["dario-catalano","Dario Fiore","rosario-gennaro","Emmanuele Giunta"],"venue":"","doi":"","publication_types":["Report"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Vector Commitments allow one to (concisely) commit to a vector of messages so that one can later (concisely) open the commitment at selected locations. In the state of the art of vector commitments, algebraic constructions have emerged as a particularly useful class, as they enable advanced properties, such as stateless updates, subvector openings and aggregation, that are for example unknown in Merkle-tree-based schemes. In spite of their popularity, algebraic vector commitments remain poorly understood objects. In particular, no construction in standard prime order groups (without pairing) is known.</p>\n<p>In this paper, we shed light on this state of affairs by showing that a large class of concise algebraic vector commitments in pairing-free, prime order groups are impossible to realize.</p>\n<p>Our results also preclude any cryptographic primitive that implies the algebraic vector commitments we rule out, as special cases.\nThis means that we also show the impossibility, for instance, of succinct polynomial commitments and functional commitments (for all classes of functions including linear forms) in pairing-free groups of prime order.</p>\n"},{"slug":"stathakopoulou2022","title":"State machine replication scalability made simple","date":"2022-04-20T00:00:00.000Z","authors":["Chrysoula Stathakopoulou","matej-pavlovic","marko-vukolic"],"venue":"EuroSys '22: Seventeenth European Conference on Computer Systems","doi":"10.1145/3492321.3519579","publication_types":["conference-paper"],"areas":["distributed-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Consensus, state machine replication (SMR) and total order broadcast (TOB) protocols are notorious for being poorly scalable with the number of participating nodes. Despite the recent race to reduce overall message complexity of leader-driven SMR/TOB protocols, scalability remains poor and the throughput is typically inversely proportional to the number of nodes. We present Insanely Scalable State Machine Replication, a generic construction to turn leader-driven protocols into scalable multi-leader ones. For our scalable SMR construction we use a novel primitive called Sequenced (Total Order) Broadcast (SB) which we wrap around PBFT, HotStuff and Raft leader-driven protocols to make them scale. Our construction is general enough to accommodate most leader-driven ordering protocols (BFT or CFT) and make them scale. Our implementation improves the peak throughput of PBFT, HotStuff, and Raft by 37x, 56x, and 55x, respectively, at a scale of 128 nodes.</p>\n"},{"slug":"campanelli2022","title":"Witness-authenticated key exchange revisited: Improved models, simpler constructions, extensions to groups","date":"2022-04-08T00:00:00.000Z","authors":["matteo-campanelli","rosario-gennaro","Kelsey Melissaris","luca-nizzardo"],"venue":"","doi":"","publication_types":["report"],"areas":["cryptography","distributed-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>We revisit the notion of Witness Authenticated Key Exchange (WAKE) where a party can be authenticated through a generic witness to an NP statement. We point out shortcomings of previous definitions, protocols and security proofs in Ngo et al. (Financial Cryptography 2021) for the (unilaterally-authenticated) two-party case. In order to overcome these limitations we introduce new models and protocols, including the first definition in literature of group witness-authenticated key exchange. We provide simple constructions based on (succinct) signatures of knowledge. Finally, we discuss their concrete performance for several practical applications in highly decentralized networks.</p>\n"},{"slug":"delarocha2022","title":"Hierarchical consensus: A horizontal scaling framework for blockchains","date":"2022-03-11T00:00:00.000Z","authors":["alfonso-delarocha","Lefteris Kokoris-Kogias","jorge-soares","marko-vukolic"],"venue":"DINPS 22","doi":"","publication_types":["conference-paper"],"areas":["distributed-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>We present the Filecoin Hierarchical Consensus framework, which aims to overcome the throughput challenges of blockchain consensus by horizontally scaling the network. Unlike traditional sharding designs, based on partitioning the state of the network, our solution centers on the concept of subnets --which are organized hierarchically-- and can be spawned on-demand to manage new state.  Child subnets are firewalled from parent subnets, have their own specific policies, and run a different consensus algorithm, increasing the network capacity and enabling new applications. Moreover, they benefit from the security of parent subnets by periodically checkpointing state. In this paper, we introduce the overall system architecture, our detailed designs for cross-net transaction handling, and the open questions that we are still exploring.</p>\n"},{"slug":"Azouvi2022a","title":"Decentralisation conscious players and system reliability","date":"2022-01-26T00:00:00.000Z","authors":["sarah-azouvi","Alexander Hicks"],"venue":"Financial Cryptography and Data Security 2022","doi":"","publication_types":["conference-paper"],"areas":["distributed-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>We propose a game-theoretic model of the reliability of de- centralised systems based on Varian’s model of system reliability [27], to which we add a new normalized total effort case that models decentrali- sation conscious players that prioritize decentralisation.\nWe derive the Nash equilibria in the normalized total effort game. In these equilibria, either one or two values are played by players that do not free ride. The speed at which players can adjust their contributions can determine how an equilibrium is reached and equilibrium values. The behaviour of decentralisation conscious players is robust to deviations by other players.\nOur results highlight the role that decentralisation conscious players can play in maintaining decentralisation. They also highlight, however, that by supporting an equilibrium that requires an important contribution they cannot be expected to increase decentralisation as contributing the equilibrium value may still imply a loss for many players. We also discuss practical constraints on decentralisation in the context of our model.</p>\n"},{"slug":"Azouvi2022","title":"Sliding window challenge process for congestion detection","date":"2022-01-24T00:00:00.000Z","authors":["Ayelet Lotem","sarah-azouvi","Aviv Zohar","Patrick McCorry"],"venue":"Financial Cryptography and Data Security 2022","doi":"","publication_types":["conference-paper"],"areas":["distributed-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Many prominent smart contract applications such as payment channels, auctions, and voting systems often involve a mechanism in which some party must respond to a challenge or appeal some action within a fixed time limit. This pattern of challenge-response mechanisms poses great risks if, during periods of high transaction volume, the network becomes congested. In this case, fee market competition can prevent the inclusion of the response in blocks, causing great harm. As a result, responders are allowed long periods to submit their response and overpay in fees. To overcome these problems and improve challenge-response protocols, we suggest a secure mechanism that detects congestion in blocks and adjusts the deadline of the response accordingly. The responder is thus guaranteed a deadline extension should congestion arise. We lay theoretical foundations for congestion signals in blockchains and then proceed to analyze and discuss possible attacks on the mechanism and evaluate its robustness. Our results show that in Ethereum, using short response deadlines as low as 3 hours, the protocol has > 99% defense rate from attacks even by miners with up to 33% of the computational power. Using shorter deadlines such as one hour is also possible with a similar defense rate for attackers with up to 27% of the power.</p>\n"},{"slug":"vukolic2021","title":"On the future of decentralized computing","date":"2021-11-23T00:00:00.000Z","authors":["marko-vukolic"],"venue":"Bulletin of the European Association for Theoretical Computer Science","doi":"","publication_types":["journal-article"],"areas":["distributed-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Decentralized systems (e.g., blockchain systems) have the potential to revolutionize financial and payment systems, as well as the internet — for the good of humankind and planet Earth. This position paper aims at justifying this standpoint and at laying out a vision for the future of decentralized computing.</p>\n<p>We start by revisiting the definition of decentralized systems, briefly surveying the literature on the taxonomy and different facets of decentralization. We complement existing definitions by proposing Inclusiveness as a critical facet. We argue that our notion of Inclusiveness rules out some popular candidate technologies for a “base-level” (or L1) blockchain consensus, namely Proof-of-Stake, from replacing Nakamoto’s Proof-of-Work (PoW) as the base consensus technology of decentralized systems.</p>\n<p>We further discuss why the high energy consumption of Bitcoin’s PoW consensus is not wasteful and why Bitcoin should be embraced as the money of the future. We then argue that future decentralized systems should aim at leveraging the “slow-but-very-secure” PoW consensus of Bitcoin, building systems on top of it rather than trying to replace it. Finally, we propose some open problems for decentralized cloud computing research.</p>\n"},{"slug":"azouvi2021a","title":"Private attacks in longest chain proof-of-stake protocols with single secret leader elections","date":"2021-11-16T00:00:00.000Z","authors":["sarah-azouvi","Daniele Cappelletti"],"venue":"AFT '21: 3rd ACM Conference on Advances in Financial Technologies","doi":"","publication_types":["conference-paper"],"areas":["distributed-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Single Secret Leader Elections have recently been proposed as an improved leader election mechanism for proof-of-stake (PoS) blockchains. However, the security gain they provide has not been quantified. In this work, we present a comparison of PoS longest-chain protocols that are based on Single Secret Leader Elections (SSLE) - that elect exactly one leader per round - versus those based on Probabilistic Leader Elections (PLE) - where one leader is elected on expectation. Our analysis shows that when considering the private attack - the worst attack on longest-chain protocols - the security gained from using SSLE is substantial: the settlement time is decreased by roughly 25% for a 33% or 25% adversary. Furthermore, when considering grinding attacks, we find that the security threshold is increased by 10% (from 0.26 in the PLE case to 0.36 inthe SSLE case) and the settlement time is decreased by roughly 70% for a 20% adversary in the SSLE case.</p>\n"},{"slug":"izabachene2021","title":"MyOPE: Malicious security for oblivious polynomial evaluation","date":"2021-09-27T00:00:00.000Z","authors":["Malika Izabachène","anca-nitulescu","Paola de Perthuis","David Pointcheval"],"venue":"SCN 2022","doi":"","publication_types":["conference-paper"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Oblivious Polynomial Evaluation (OPE) schemes are interactive protocols between a\nsender with a private polynomial and a receiver with a private evaluation point where the receiver learns the evaluation of the polynomial in their point and no additional information. They are used in Private Set Intersection (PSI) protocols.</p>\n<p>We introduce a scheme for OPE in the presence of malicious senders, enforcing honest sender\nbehavior and consistency by adding verifiability to the calculations. The main tools used are FHE for input privacy and arguments of knowledge for the verifiability property. MyOPE deploys sublinear communication costs in the sender’s polynomial degree and one to five rounds of interaction. In other words, it can be used as a verifiable computation scheme for polynomial evaluation over FHE ciphertexts. While classical techniques in pairing-based settings allow generic succinct proofs for such evaluations, they require large prime order subgroups which highly impact the communication complexity, and prevent the use of FHE with practical parameters. MyOPE builds on generic secure encodings techniques that allow composite integers and enable real-world FHE parameters and even RNS-based optimizations. It is best adapted for the unbalanced setting where the degree of the polynomial and the computing power of the sender are large.</p>\n<p>MyOPE can be used as a building block in specialized two-party protocols such as PSI (this use case is hereafter described), oblivious keyword search, set membership and more using the OPE instantiation. As another contribution, our techniques are generalized to applications other than OPE, such as Symmetric Private Information Retrieval (SPIR), to make them secure against a malicious sender.</p>\n"},{"slug":"aranha2021","title":"Count me in! Extendability for threshold ring signatures","date":"2021-09-21T00:00:00.000Z","authors":["Diego Aranha","Mathias Hall-Anderson","anca-nitulescu","Elena Pagnin","Sophia Yakoubov"],"venue":"PKC 2022","doi":"","publication_types":["conference-paper"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Ring signatures enable a signer to sign a message on behalf of a group anonymously, without\nrevealing her identity. Similarly, threshold ring signatures allow several signers to sign the same message\non behalf of a group; while the combined signature reveals that some threshold t of the group members\nsigned the message, it does not leak anything else about the signers’ identities. Anonymity is a central\nfeature in threshold ring signature applications, such as whistleblowing, e-voting and privacy-preserving\ncryptocurrencies: it is often crucial for signers to remain anonymous even from their fellow signers. When\nthe generation of a signature requires interaction, this is difficult to achieve. There exist threshold ring\nsignatures with non-interactive signing — where signers locally produce partial signatures which can\nthen be aggregated — but a limitation of existing threshold ring signature constructions is that all\nof the signers must agree on the group on whose behalf they are signing, which implicitly assumes\nsome coordination amongst them. The need to agree on a group before generating a signature also\nprevents others — from outside that group — from endorsing a message by adding their signature to\nthe statement post-factum.\nWe overcome this limitation by introducing extendability for ring signatures, same-message linkable\nring signatures, and threshold ring signatures. Extendability allows an untrusted third party to take\na signature, and extend it by enlarging the anonymity set to a larger set. In the extendable threshold\nring signature, two signatures on the same message which have been extended to the same anonymity\nset can then be combined into one signature with a higher threshold. This enhances signers’ anonymity,\nand enables new signers to anonymously support a statement already made by others.\nFor each of those primitives, we formalize the syntax and provide a meaningful security model which\nincludes different flavors of anonymous extendability. In addition, we present concrete realizations of\neach primitive and formally prove their security relying on signatures of knowledge and the hardness\nof the discrete logarithm problem. We also describe a generic transformation to obtain extendable\nthreshold ring signatures from same-message-linkable extendable ring signatures. Finally, we implement\nand benchmark our constructions.</p>\n"},{"slug":"antunes2021","title":"Pulsarcast: Scalable, reliable pub-sub over P2P nets","date":"2021-06-21T00:00:00.000Z","authors":["Joao Antunes","david-dias","Luis Veiga"],"venue":"DI2F","doi":"","publication_types":["conference paper"],"areas":["distributed-systems","networking"],"abstract":"","url_pdf":"","url_source":"","html":"<p>The publish-subscribe paradigm is a wildly popular\nform of communication in complex distributed systems. The properties\noffered by it make it an ideal solution for a multitude of\napplications, ranging from social media to content streaming and\nstock exchange platforms. Consequently, a lot of research exists\naround it, with solutions ranging from centralised message brokers,\nto fully decentralised scenarios (peer to peer).\nWithin the pub-sub realm not every solution is the same of course\nand trade-offs are commonly made between the ability to distribute\ncontent as fast as possible or having the assurance that all the\nmembers of the network will receive the content they have subscribed\nto. Delivery guarantees is something quite common within the area\nof centralised pub-sub solutions, there is, however, a clear lack\nof decentralised systems accounting for this. Specifically, a reliable\nsystem with the ability to provide message delivery guarantees and,\nmore importantly, persistence guarantees. To this end, we present\nPulsarcast, a decentralised, highly scalable, pub-sub, topic based\nsystem seeking to give guarantees that are traditionally associated\nwith a centralised architecture, such as persistence and eventual\ndelivery guarantees.\nThe aim of Pulsarcast is to take advantage of the network\ninfrastructure and protocols already in place. Relying on a structured\noverlay and a graph based data structure, we build a set of\ndissemination trees through which our events will be distributed.\nOur work also encompasses a software module that implements\nPulsarcast, with our experimental results showing that is a viable\nand quite promising solution within the pub-sub and peer to peer\necosystem.</p>\n"},{"slug":"psaras2021","title":"The case for AI based Web3 reputation systems","date":"2021-06-21T00:00:00.000Z","authors":["Navin V. Keizer","Fan Yang","yiannis-psaras","George Pavlou"],"venue":"DI2F","doi":"","publication_types":["conference paper"],"areas":["distributed-systems","networking"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Initiatives such as blockchains and decentralized\nstorage networks are pushing for a decentralized Web3 to replace\nthe current architecture. At the core of Web3 are network\nresource sharing services, which allow anyone to sell spare\nnetwork capacity in return for rewards. These services require a\nway to establish trust, as parties are potentially malicious. This\ncan be achieved by reputation systems.</p>\n<p>In this paper we make the case for using deep reinforcement\nlearning in Web3 reputation calculation. More specifically, we\npropose a model which allows for decentralized ca</p>\n"},{"slug":"delarocha2021a","title":"IPFS-FAN: A function-addressable computation network","date":"2021-06-11T00:00:00.000Z","authors":["alfonso-delarocha","yiannis-psaras","david-dias"],"venue":"DI2F","doi":"","publication_types":["conference-paper"],"areas":["networking","distributed-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Permissionless computation is one of the missing pieces in the web3 stack in order to have all the tools needed to “decentralise Internet services”. There are already proposals to embed computation in decentralised networks like smart contracts, or blockchain networks for computational offloading. Although technically sound, their computational model is too restrictive to be used for general purpose computation.</p>\n<p>In this paper, we propose a general architecture of a decentralised network for general-purpose and permissionless computation based on content-addressing. We present a proof-of-concept prototype and describe in detail its building blocks.</p>\n"},{"slug":"gailly2021","title":"SnarkPack: Practical SNARK aggregation","date":"2021-05-13T00:00:00.000Z","authors":["nicolas-gailly","Mary Maller","anca-nitulescu"],"venue":"Financial Cryptography and Data Security 2022","doi":"","publication_types":["conference-paper"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Zero-knowledge SNARKs (zk-SNARKs) are non-interactive proof systems with short and efficiently verifiable proofs. zk-SNARKs are widely used in decentralised systems to address privacy and scalability concerns. One of the main applications is the blockchain, were SNARKs are used to prove computations with private inputs and reduce on-chain footprint verification and transaction sizes.</p>\n<p>We design and implement SnarkPack, a new argument that further reduces the size of SNARK proofs by means of aggregation. Our goal is to provide an off-the-shelf solution that is practical in the following sense: (1) it is compatible with existing deployed systems, (2) it does not require any extra setup.</p>\n<p>SnarkPack is designed to work with Groth16 scheme and has logarithmic size proofs and a verifier that runs in logarithmic time in the number of proofs to be aggregated. Most importantly, SnarkPack reuses the public parameters from Groth16 system, so it does not require a separate trusted setup ceremony.</p>\n<p>The key tool for our construction is a new commitment scheme that uses as public parameters two existing ”powers of tau” ceremony transcripts. The commitment scheme allows us to instantiate the inner product pairing arguments (IPP) of Bünz et al. without additional trusted setup.</p>\n<p>SnarkPack can aggregate 8192 proofs in 8.7s and verify them in 33ms, including un-serialization time, yielding a verification mechanism that is exponentially faster than batching and previous solutions in the field.</p>\n"},{"slug":"ganesh2021","title":"Rinocchio: SNARKs for ring arithmetic","date":"2021-03-18T00:00:00.000Z","authors":["Chaya Ganesh","anca-nitulescu","Eduardo Soria-Vazquez"],"venue":"","doi":"","publication_types":["report"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Succinct non-interactive arguments of knowledge (SNARKs) enable non-interactive efficient verification of NP computations and admit short proofs. However, all current SNARK constructions assume that the statements to be proven can be efficiently represented as either Boolean or arithmetic circuits over finite fields. For most constructions, the choice of the prime field $F_p$ is limited by the existence of groups of matching order for which secure bilinear maps exist.</p>\n<p>In this work, we overcome such restrictions and enable verifying computations over rings. We construct the first designated-verifier SNARK for statements which are represented as circuits over a broader kind of commutative rings, namely those containing big enough <em>exceptional set</em>. Exceptional sets consist of elements such that their pairwise differences are invertible. Our contribution is threefold: We first introduce Quadratic Ring Programs (QRPs) as a characterization of NP where the arithmetic is over a ring and we generalize pre-existent assumptions employed in field-restricted SNARKs to the ring context.</p>\n<p>We construct ring SNARKs from framework based on encodings, inspired by the Pinocchio. Our scheme is modular, based on generic encodings over rings and allows for various instantiations in order to adapt to different settings. Finally, we propose two applications for our SNARKs. In the first one, we instantiate our construction for the Galois Rings $GR(2^k,d)$, i.e. the degree-<em>d</em> Galois extension of  $Z_{2^k}$. This allows us to naturally prove statements about circuits over  $Z_{2^{64}}$, which closely matches real-life computer architectures such as standard CPUs. Our second application is verifiable computation over encrypted data, specifically for evaluations of Ring-LWE-based homomorphic encryption schemes.</p>\n"},{"slug":"delarocha2021","title":"Accelerating content routing with Bitswap: A multi-path file transfer protocol in IPFS and Filecoin","date":"2021-01-14T00:00:00.000Z","authors":["alfonso-delarocha","david-dias","yiannis-psaras"],"venue":"","doi":"","publication_types":["report"],"areas":["distributed-systems","networking"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Bitswap   is   a   Block   Exchange   protocol   designed for  P2P  Content  Addressable  Networks.  It  leverages  merkle-linked graphs in order to parallelize retrieval and verify content integrity. Bitswap is being used in the InterPlanetary File System architecture  as  the  main  content  exchange  protocol,  as  well  as in  the  Filecoin  network  as  part  of  the  block  synchronisation protocol. In this work, we present Bitswap’s baseline design and then  apply  several  new  extensions  with  the  goal  of  improving Bitswap’s  efficiency and  efficacy  and  minimizing  its  bandwidth  fingerprint. Most importantly, our extensions result in a substantial increase to the protocol’s content discovery rate. This is achieved by  using  the  wealth  of  information  that  the  protocol  acquires from  the  content  routing  subsystem  to  make  smarter  decisions on  where  to  fetch  the  content  from.</p>\n"},{"slug":"ransil2020","title":"Improving system resilience through formal verification of transactive energy controls","date":"2020-12-09T00:00:00.000Z","authors":["michael-hammersley","Francis M. O'Sullivan","alan-ransil"],"venue":"IEEE PES Transactive Energy Systems Conference (TESC)","doi":"","publication_types":["conference-paper"],"areas":["distributed-power-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Formal verification tools such as TLA+ allow errors\nto be uncovered through exhaustive exploration of reachable\nstates, and are the gold standard for ensuring resilience in\nsoftware systems. In particular, these methods can be used to\nidentify error states emerging from precise interactions between\nmultiple subsystems that would occur only after long periods of\ntesting, operation, or stacked error conditions. This approach\nhas been applied to eliminate errors in commercial software\nsystems, networking, industrial controls, and increasingly in\nenergy applications. We have recently demonstrated the use\nof standard distribution feeders as a basis for TLA+ models\nin order to provide a test setup for investigating distributed\nenergy control algorithms. Here we examine a distribution feeder\nunder conditions in which a transmission outage curtails slack\nbus power flows. While conventional grid architectures under\nthese conditions would de-energize the feeder and require nodes\nwith distributed energy resources (DERs) to operate in islanded\nmode, we model control algorithms for a transactive energy\nsystem in which DERs are able to sell power to neighboring\nnodes. A modular architecture is used to add new node and\nfeeder capabilities, such as the ability to buy and sell energy\nin hyperlocal distribution markets, as module upgrades while\ncontaining modifications to the control system used to operate the\nfeeder. This approach allows the resiliency benefits of transactive\nenergy to be gained while minimizing implementation costs\nthrough the reduction of complexity. We model a laminar\ncoordination framework and use TLA+ to formally verify its\noperation. Using this formal specification, we investigate the\nlatency of coordination signals over a range of system states\nand identify conditions for stable operation. We show that while\nallowing energy transactions between peers on a feeder improves\nsystem resilience by permitting continued operation despite the\nfailure of transmission infrastructure, care must be taken to\naddress other failure modes that arise from this decentralized\narchitecture which can be addressed through model checking.\nThis work establishes formal verification as an invaluable tool\nfor realization of the resiliency benefits of transactive energy by\nuncovering potential failure modes and providing engineers a\nchance to mitigate them before systems are commissioned.</p>\n"},{"slug":"psaras2020b","title":"PASTRAMI: Privacy-preserving, auditable, scalable & trustworthy auctions for multiple items","date":"2020-12-07T00:00:00.000Z","authors":["Michał Król","Alberto Sonnino","Argyrios Tasiopoulos","yiannis-psaras","Etienne Rivière"],"venue":"Middleware '20","doi":"","publication_types":["conference-paper"],"areas":["distributed systems","networking"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Decentralised cloud computing platforms enable individuals\nto offer and rent resources in a peer-to-peer fashion. They\nmust assign resources from multiple sellers to multiple buyers\nand derive prices that match the interests and capacities of\nboth parties. The assignment process must be decentralised,\nfair and transparent, but also protect the privacy of buyers.</p>\n<p>We present PASTRAMI, a decentralised platform enabling\ntrustworthy assignments of items and prices between a large\nnumber of sellers and bidders, through the support of multi-item\nauctions. PASTRAMI uses threshold blind signatures and commitment\nschemes to provide strong privacy guarantees while making bidders\naccountable. It leverages the Ethereum blockchain for auditability,\ncombining efficient off-chain computations with novel, on-chain\nproofs of misbehaviour. Our evaluation of PASTRAMI using Filecoin\nworkloads show its ability to efficiently produce trustworthy\nassignments between thousands of buyers and sellers.</p>\n"},{"slug":"campanelli2020","title":"Incrementally aggregatable vector commitment techniques and applications to verifiable decentralized storage","date":"2020-12-05T00:00:00.000Z","authors":["Matteo Campanelli","Dario Fiore","nicola-greco","Dimitris Kolonelos","luca-nizzardo"],"venue":"Advances in Cryptology – ASIACRYPT 2020","doi":"","publication_types":["report"],"areas":["cryptography","distributed-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Vector commitments with subvector openings (SVC) [Lai-Malavolta, Boneh-Bunz-Fisch; CRYPTO’19] allow one to open a committed vector at a set of positions with an opening of size independent of both the vector’s length and the number of opened positions.</p>\n<p>We continue the study of SVC with two goals in mind: improving their efficiency and making them more suitable to decentralized settings. We address both problems by proposing a new notion for VC that we call incremental aggregation and that allows one to merge openings in a succinct way an unbounded number of times. We show two applications of this property. The first one is immediate and is a method to generate openings in a distributed way. The second application is an algorithm for faster generation of openings via preprocessing.</p>\n<p>We then proceed to realize SVC with incremental aggregation. We provide two constructions in groups of unknown order that, similarly to that of Boneh et al. (which supports aggregating only once), have constant-size public parameters, commitments and openings. As an additional feature, for the first construction we propose efficient arguments of knowledge of subvector openings which immediately yields a keyless proof of storage with compact proofs.</p>\n<p>Finally, we address a problem closely related to that of SVC: storing a file efficiently in completely decentralized networks. We introduce and construct verifiable decentralized storage (VDS), a cryptographic primitive that allows to check the integrity of a file stored by a network of nodes in a distributed and decentralized way. Our VDS constructions rely on our new vector commitment techniques.</p>\n"},{"slug":"faonio2020","title":"Subversion-resilient enhanced privacy ID","date":"2020-11-17T00:00:00.000Z","authors":["Antonio Faonio","Dario Fiore","luca-nizzardo","Claudio Soriente"],"venue":"Cryptographers’ Track at the RSA Conference","doi":"10.1007/978-3-030-95312-6_23","publication_types":["conference-paper"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Anonymous attestation for secure hardware platforms leverages tailored group signature schemes and assumes the hardware to be trusted. Yet, there is an increasing concern on the trustworthiness of hardware components and embedded systems. A subverted hardware may, for example, use its signatures to exfiltrate identifying information or even the signing key. We focus on Enhanced Privacy ID (EPID)—a popular anonymous attestation scheme used in commodity secure hardware platforms like Intel SGX. We define and instantiate a subversion resilient EPID scheme (or SR-EPID). In a nutshell, SR-EPID provides the same functionality and security guarantees of the original EPID, despite potentially subverted hardware. In our design, a “sanitizer” ensures no covert channel between the hardware and the outside world both during enrollment and during attestation (i.e., when signatures are produced). We design a practical SR-EPID scheme secure against adaptive corruptions and based on a novel combination of malleable NIZKs and hash functions modeled as random oracles. Our approach has a number of advantages over alternative designs. Namely, the sanitizer bears no secret information—hence, a memory leak does not erode security. Also, we keep the signing protocol non-interactive, thereby minimizing latency during signature generation.</p>\n"},{"slug":"azouvi2021","title":"Winkle: foiling long-range attacks in proof-of-stake systems","date":"2020-10-21T00:00:00.000Z","authors":["sarah-azouvi","George Danezis","Valeria Nikolaenko"],"venue":"AFT '20: 2nd ACM Conference on Advances in Financial Technologies","doi":"","publication_types":["conference-paper"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Winkle protects any validator-based byzantine fault tolerant consensus mechanisms, such as those used in modern Proof-of-Stake\nblockchains, against long-range attacks where old validators’ signature keys get compromised. Winkle is a decentralized secondary\nlayer of client-based validation, where a client includes a single additional field into a transaction that they sign: a hash of the\npreviously sequenced block. The block that gets a threshold of signatures (confirmations) weighted by clients’ coins is called a “confirmed”\ncheckpoint. We show that under plausible and flexible security assumptions about clients the confirmed checkpoints can not be\nequivocated. We discuss how client key rotation increases security, how to accommodate for coins’ minting and how delegation\nallows for faster checkpoints. We evaluate checkpoint latency experimentally using Bitcoin and Ethereum transaction graphs, with\nand without delegation of stake.</p>\n"},{"slug":"psaras2020a","title":"Rewarding relays for decentralised NAT traversal using smart contracts","date":"2020-10-11T00:00:00.000Z","authors":["Navin V. Keizer","Onur Ascigil","yiannis-psaras","George Pavlou"],"venue":"Mobihoc '20","doi":"","publication_types":["conference-paper"],"areas":["distributed systems","networking"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Traversing NAT’s remains a big issue in P2P networks, and many of\nthe previously proposed solutions are incompatible with truly\ndecentralised emerging applications. Such applications need a\ndecentralised NAT traversal solution without trusted centralised servers.</p>\n<p>In this paper we present a decentralised, relay-based NAT traversal\nsystem, where any reachable node is able to assist an unreachable\nnode in NAT traversal. Smart contracts on the Ethereum blockchain\nare used to ensure fair rewards. Besides !nancial incentives, a\nreputation system based on transactions on-chain is used to mitigate\nagainst malicious behaviour, and guide peer discovery.</p>\n<p>Evaluation of our system shows that a combination of historic\nperformance metrics leads to an optimal scoring function, that the\nsystem takes little time to reach stability from inception, and that\nthe system is resilient against various attacks. Implementation of the\nsmart contract shows that the cost for participants is manageable.</p>\n"},{"slug":"protocol2020","title":"Engineering Filecoin’s economy","date":"2020-08-27T00:00:00.000Z","authors":["Protocol Labs"],"venue":"","doi":"","publication_types":["report"],"areas":["cryptoeconomics"],"abstract":"","url_pdf":"","url_source":"","html":"<p>As a novel data storage and distribution network, the Filecoin Network’s mission is to create a decentralized, efficient, and robust foundation for humanity’s information. This mission will be advanced by incentivizing consistent growth and development of the Filecoin Network’s economy.  The goal of the economic design is to align incentives and pragmatically reward useful and reliable storage with as few rules as possible. The action and interaction of each of these mechanisms must be considered during the design process. Other economic structures and product offerings can then emerge from these basic building blocks. This document explains specific incentive mechanisms and economic stimuli provided by the protocol itself. For each fee, reward, or penalty in the protocol, there will be an explanation of how it is intended to contribute to long-term utility of the network. Additionally, this document explains the importance of long-term cooperation between participants in the Filecoin Network.  The protocol’s design enables and incentivizes this collaboration and furthers the interests of all participants.</p>\n"},{"slug":"vyzovitis2020a","title":"GossipSub: Attack-resilient message propagation in the Filecoin and ETH2.0 networks","date":"2020-07-06T00:00:00.000Z","authors":["Dimitris Vyzovitis","Yusef Napora","Dirk McCormick","david-dias","yiannis-psaras"],"venue":"","doi":"","publication_types":["report"],"areas":["distributed-systems","networking"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Permissionless blockchain environments necessitate the use of a fast and attack-resilient message propagation protocol for Block and Transaction messages to keep nodes synchronised and avoid forks. We present GossipSub, a gossip-based pubsub protocol, which, in contrast to past pubsub protocols, incorporates resilience against a wide spectrum of attacks. Firstly, GossipSub's mesh construction implements an eager push model keeps the fan-out of the pubsub delivery low and balances excessive bandwidth consumption and fast message propagation throughout the mesh. Secondly, through gossip dissemination, GossipSub realises a lazy-pull model to reach nodes far-away or outside the mesh. Thirdly, through constant observation, nodes maintain a score profile for the peers they are connected to, allowing them to choose the most well-behaved nodes to include in the mesh. Finally, and most importantly, a number of tailor-made mitigation strategies designed specifically for these three components make GossipSub resilient against the most challenging Sybil-based attacks. We test GossipSub in a testbed environment involving more than 5000 VM nodes deployed on AWS and show that it stays immune to all considered attacks. GossipSub is currently being integrated as the main messaging layer protocol in the Filecoin and the Ethereum 2.0 (ETH2.0) blockchains.</p>\n"},{"slug":"seemann2020","title":"Automating QUIC interoperability testing","date":"2020-06-12T00:00:00.000Z","authors":["marten-seemann","Jana Iyengar"],"venue":"ACM SIGCOMM 2020 Workshop on Evolution, Performance, and Interoperability of QUIC","doi":"","publication_types":["conference-paper"],"areas":["networking"],"abstract":"","url_pdf":"","url_source":"","html":"<p>We present QuicInteropRunner [1,2], a test framework for automated and on-demand interoperability testing between implementations of the QUIC protocol [3]. We describe the key constraints and insights that defined our work, the recent innovations that made the framework possible, a high-level overview of our design, and a few exemplary tests. QuicInteropRunner is now supported and used by ten QUIC implementations as part of their development process, confirming our thesis that there is a need for automating interoperability testing and making it available on demand.</p>\n"},{"slug":"psaras2020","title":"Merkle-CRDTs: Merkle-DAGs meet CRDTs","date":"2020-04-27T00:00:00.000Z","authors":["Hector Sanjuan","Samuli Poyhtari","Pedro Teixeira","yiannis-psaras"],"venue":"","doi":"","publication_types":[null],"areas":["distributed-systems","networking"],"abstract":"","url_pdf":"","url_source":"","html":"<p>We study Merkle-DAGs as a transport and persistence layer\nfor Conflict-Free Replicated Data Types (CRDTs),\ncoining the term Merkle-CRDTs and providing an overview of\nthe different concepts, properties, advantages and limitations\ninvolved. We show how Merkle-DAGs can act as logical clocks\ngiving Merkle-CRDTs the potential to greatly simplify the design\nand implementation of convergent data types in systems with\nweak messaging layer guarantees and a very large number of\nreplicas. Merkle-CRDTs can leverage highly scalable distributed\ntechnologies like DHTs and PubSub algorithms running underneath\nto take advantage of the security and de-duplication properties of\ncontent-addressing. Examples of such contentoriented systems could\ninclude peer-to-peer content exchange and synchronisation applications\nbetween opportunistically connected mobile devices, IoT devices\nor user applications running in a web browser.</p>\n"},{"slug":"vyzovitis2020","title":"Gossipsub-v1.1 evaluation report","date":"2020-04-18T00:00:00.000Z","authors":["Dimitris Vyzovitis","Yusef Napora","Dirk McCormick","david-dias","yiannis-psaras"],"venue":"","doi":"","publication_types":["report"],"areas":["distributed-systems","networking"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Permissionless blockchain environments necessitate the use of a fast and attack-resilient message propagation protocol for Block and Transaction messages to keep nodes synchronised and avoid forks. We present GossipSub, a gossip-based pubsub protocol, which, in contrast to past pubsub protocols, incorporates resilience against a wide spectrum of attacks.</p>\n<p>Firstly, GossipSub’s mesh construction implements an eager push model keeps the fan-out of the pubsub delivery low and balances excessive bandwidth consumption and fast message propagation throughout the mesh. Secondly, through gossip dissemination, GossipSub realises a lazy-pull model to reach nodes far-away or outside the mesh. Thirdly, through constant observation, nodes maintain a score profile for the peers they are connected to, allowing them to choose the most well-behaved nodes to include in the mesh. Finally, and most importantly, a number of tailor-made mitigation strategies designed specifically for these three components make GossipSub resilient against the most challenging Sybil-based attacks. We test GossipSub in a testbed environment involving more than 5000 VM nodes deployed on AWS and show that it stays immune to all considered attacks. GossipSub is currently being integrated as the main messaging layer protocol in the Filecoin and the Ethereum 2.0 (ETH2.0) blockchains.</p>\n"},{"slug":"catalano2019","title":"MonZa: Fast maliciously secure two party computation on Z_{2^k}","date":"2020-04-08T00:00:00.000Z","authors":["Dario Catalano","Mario Di Raimondo","Dario Fiore","irene-giacomelli"],"venue":"IACR International Conference on Practice and Theory of Public-Key Cryptography (PKC)","doi":"","publication_types":["conference-paper"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"","html":"<p>In this paper we present a new 2-party protocol for secure computation over rings of the form Z2k. As many recent efficient MPC protocols supporting dishonest majority, our protocol consists of a heavier (input-independent) pre-processing phase and a very efficient online stage. Our offline phase is similar to BeDOZa (Bendlin et al. Eurocrypt 2011) but employs Joye-Libert (JL, Eurocrypt 2013) as underlying homomorphic cryptosystem and, notably, it can be proven secure without resorting to the expensive sacrifice step. JL turns out to be particularly well suited for the ring setting as it naturally supports Z2k as underlying message space. Moreover, it enjoys several additional properties (such has valid ciphertext-verifiability and efficiency) that make it a very good fit for MPC in general. As a main technical contribution we show how to take advantage of all these properties (and of more properties that we introduce in this work, such as a ZK proof of correct multiplication) in order to design a two-party protocol that is efficient, fast and easy to implement in practice. Our solution is particularly well suited for relatively large choices of k (e.g., k=128), but compares favorably with the state of the art solution of SPDZ2k (Cramer et al. Crypto 2018) already for the practically very relevant case of k=64.</p>\n"},{"slug":"santos2019","title":"Censorship-resistant web annotations based on Ethereum and IPFS","date":"2020-03-30T00:00:00.000Z","authors":["João Santos","Nuno Santos","david-dias"],"venue":"SAC 2020","doi":"","publication_types":["conference-paper"],"areas":["distributed-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Flooded by the propagation of false or biased news in the Web, people tend to resort to social networks to read posts from reliable sources, exchange commentaries with trustworthy parties, access first-hand content, or cross-check information that appears in news outlets. However, platform providers like Facebook or Twitter can ultimately decide about the contents exposed to each user. Anecdotal evidence suggests that such platform providers are prone to pressure by political or economical agents, and may be ideologically driven to hide messages or block certain users, thereby impairing users' ability to freely access rightful information.</p>\n"},{"slug":"azouvi2020","title":"SoK: Tools for game theoretic models of security for cryptocurrencies","date":"2020-03-03T00:00:00.000Z","authors":["sarah-azouvi","Alexander Hicks"],"venue":"Cryptoeconomic Systems","doi":"","publication_types":["conference-paper"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Cryptocurrencies have garnered much attention in recent years, both from the academic community and industry. One interesting aspect of cryptocurrencies is their explicit consideration of incentives at the protocol level, which has motivated a large body of work, yet many open problems still exist and current systems rarely deal with incentive related problems well. This issue arises due to the gap between Cryptography and Distributed Systems security, which deals with traditional security problems that ignore the explicit consideration of incentives, and Game Theory, which deals best with situations involving incentives. With this work, we offer a systematization of the work that relates to this problem, considering papers that blend Game Theory with Cryptography or Distributed systems. This gives an overview of the available tools, and we look at their (potential) use in practice, in the context of existing blockchain based systems that have been proposed or implemented.</p>\n"},{"slug":"boneh2020","title":"Single secret leader election","date":"2020-01-15T00:00:00.000Z","authors":["Dan Boneh","Saba Eskandarian","Lucjan Hanzlik","nicola-greco"],"venue":"ACM Advances in Financial Technologies 2020","doi":"","publication_types":["conference-paper"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"","html":"<p>In a Single Secret Leader Election (SSLE), a group of participants aim to randomly choose exactly one leader from the group with the restriction that the identity of the leader will be known to the chosen leader and nobody else. At a later time, the elected leader should be able to publicly reveal her identity and prove that she has won the election. The election process itself should work properly even if many registered users are passive and do not send any messages. Among the many applications of SSLEs, their potential for enabling more efficient proof-of-stake based cryptocurrencies have recently received increased attention.</p>\n<p>This paper formally defines SSLE schemes and presents three constructions that provide varying security and performance properties. First, as an existence argument, we show how to realize an ideal SSLE using indistinguishability obfuscation. Next, we show how to build SSLE from low-depth threshold fully homomorphic encryption (TFHE) via a construction which can be instantiated with a circuit of multiplicative depth as low as 10, for realistically-sized secret leader elections. Finally, we show a practical scheme relying on DDH that achieves a slightly relaxed notion of security but which boasts extremely lightweight computational requirements.</p>\n"},{"slug":"chandrasekaran2019","title":"Exploring connections between active learning and model extraction","date":"2019-11-20T00:00:00.000Z","authors":["Varun Chandrasekaran","Kamalika Chaudhuri","irene-giacomelli","Somesh Jha","Songbai Yan"],"venue":"","doi":"","publication_types":["report"],"areas":[null],"abstract":"","url_pdf":"","url_source":"","html":"<p>Machine learning is being increasingly used by individuals, research institutions, and corporations. This has resulted in the surge of Machine Learning-as-a-Service (MLaaS) - cloud services that provide (a) tools and resources to learn the model, and (b) a user-friendly query interface to access the model. However, such MLaaS systems raise privacy concerns such as model extraction. In model extraction attacks, adversaries maliciously exploit the query interface to steal the model. More precisely, in a model extraction attack, a good approximation of a sensitive or proprietary model held by the server is extracted (i.e. learned) by a dishonest user who interacts with the server only via the query interface. This attack was introduced by Tramer et al. at the 2016 USENIX Security Symposium, where practical attacks for various models were shown. We believe that better understanding the efficacy of model extraction attacks is paramount to designing secure MLaaS systems. To that end, we take the first step by (a) formalizing model extraction and discussing possible defense strategies, and (b) drawing parallels between model extraction and established area of active learning. In particular, we show that recent advancements in the active learning domain can be used to implement powerful model extraction attacks, and investigate possible defense strategies.</p>\n"},{"slug":"giacomelli2019","title":"Efficient UC commitment extension with homomorphism for free (and applications)","date":"2019-10-02T00:00:00.000Z","authors":["Ignacio Cascudo","Ivan Damgård"," Bernardo David","Nico Döttling","Rafael Dowsley","irene-giacomelli"],"venue":"Advances in Cryptology – ASIACRYPT 2019","doi":"","publication_types":["conference paper"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Homomorphic universally composable (UC) commitments allow for the sender to reveal the\nresult of additions and multiplications of values contained in commitments without revealing the values\nthemselves while assuring the receiver of the correctness of such computation on committed values. In\nthis work, we construct essentially optimal additively homomorphic UC commitments from any (not\nnecessarily UC or homomorphic) extractable commitment. We obtain amortized linear computational\ncomplexity in the length of the input messages and rate 1. Next, we show how to extend our scheme\nto also obtain multiplicative homomorphism at the cost of asymptotic optimality but retaining low\nconcrete complexity for practical parameters. While the previously best constructions use UC oblivious\ntransfer as the main building block, our constructions only require extractable commitments and PRGs,\nachieving better concrete efficiency and offering new insights into the sufficient conditions for obtaining\nhomomorphic UC commitments. Moreover, our techniques yield public coin protocols, which are compatible with\nthe Fiat-Shamir heuristic. These results come at the cost of realizing a restricted version\nof the homomorphic commitment functionality where the sender is allowed to perform any number of\ncommitments and operations on committed messages but is only allowed to perform a single batch\nopening of a number of commitments. Although this functionality seems restrictive, we show that it can\nbe used as a building block for more efficient instantiations of recent protocols for secure multiparty\ncomputation and zero knowledge non-interactive arguments of knowledge.</p>\n"},{"slug":"dalrymple2019","title":"Dioptics: A common generalization of open games and gradient-based learners","date":"2019-09-05T00:00:00.000Z","authors":["david-dalrymple"],"venue":"Fifth Symposium on Compositional Structures (SYCO)","doi":"","publication_types":["conference-paper"],"areas":["applied-category-theory"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Compositional semantics have been shown for machine-learning algorithms [FST18] and open games [Hed18]; at SYCO 1, remarks were made noting the high degree of overlap in character and analogy between the constructions, and that there is known to be a monoidal embedding from the category of learners to the category of games, but it remained unclear exactly what kind of structure they both are. This is work in progress toward showing that both categories embed faithfully and bijectively-on-objects into instances of a pattern we call categories of dioptics, whose name and definition both build heavily on [Ril18]. Using a generalization of the reverse-mode automatic differentiation functor of [Ell18] to arbitrary diffeological spaces with trivializable tangent bundles, we also construct a category of gradient-based learners which generalizes gradient-based learning beyond Euclidean parameter spaces. We aim to show that this category embeds naturally into the category of learners (with a choice of update rule and loss function), and that composing this embedding with reverse-mode automatic differentiation (and the inclusion of Euclidean spaces into trivializable diffeological spaces) recovers the backpropagation functor L of [FST18].</p>\n"},{"slug":"ransil2019a","title":"A dual-process approach for automated knowledge creation","date":"2019-09-05T00:00:00.000Z","authors":["alan-ransil","chhimed-kunzang"],"venue":"Metascience Symposium","doi":"","publication_types":["poster"],"areas":["knowledge-engineering"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Scientific knowledge growth combines elements of existing theories into new proposed models, which is combinatorially intractable. Inspired by dual-system psychological theories, we conceptualize a knowledge creation process in two stages. Stage One narrows the space of existing computational elements based on contextual queues, supplying components from which a new model will be proposed. It is trained on large datasets but is computationally inexpensive at runtime. Stage Two permutes these elements in accordance with their explicit constraints, resulting in a set of proposed computable theories. We have developed a system that implements Stage Two. This system provides robust infrastructure for expressing constraints imposed by scientific theories, supplying a framework relating theory sub-graphs to experimental datasets stored in relational databases. We demonstrate an implementation of this two-stage approach solving materials chemistry problems using experimental datasets.</p>\n"},{"slug":"hammersley2018","title":"U.S. energy policy and market design","date":"2019-09-03T00:00:00.000Z","authors":["michael-hammersley"],"venue":"","doi":"","publication_types":["report"],"areas":["distributed-power-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>The U.S. bulk power system has an enormous number of actors: regulatory agencies (local, state, and federal), utilities (investor-owned, municipal, cooperatives, and power marketing administrations), operators (ISOs and RTOs), and customers. Mandates for the bulk power system are that it be cheap, equitable, and reliable -- and, increasingly, clean or renewable. Presented herein is a digestible introduction to some of the major players (and types of players) within the system, some of the major regulatory and deregulatory milestones since the grid's inception in the early 20th century, and the functions of the U.S. electricity wholesale market.</p>\n"},{"slug":"gabizon2019a","title":"PLONK: Permutations over Lagrange-bases for oecumenical noninteractive arguments of knowledge","date":"2019-08-24T00:00:00.000Z","authors":["ariel-gabizon","Zachary J Williamson","Oana Ciobotaru"],"venue":"Stanford Blockchain Conference","doi":"","publication_types":["conference-paper"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"https://eprint.iacr.org/2019/953","html":"<p>zk-SNARK constructions that utilize an updatable universal structured reference string remove one of the main obstacles in deploying zk-SNARKs[GKM + ]. The important work of Maller et al. [MBKM19] presented Sonic-the first potentially practical zk-SNARK with fully succinct verification for general arithmetic circuits with such an SRS. However, the version of Sonic enabling fully succinct verification still requires relatively high proof construction overheads. We present a universal SNARK construction with fully succinct verification, and significantly lower prover running time (roughly 7.5-20 less group exponentiations than [MBKM19] in the fully succinct verifier mode depending on circuit structure). Similarly to [MBKM19, BCC + 16] we rely on a permutation argument based on Bayer and Groth [BG12]. However, we focus on \"Evaluations on a subgroup rather than coefficients of monomials\"; which enables simplifying both the permutation argument and the artihmetization step.</p>\n"},{"slug":"ransil2019","title":"A computable multilayer system stack for future-proof interoperability","date":"2019-07-09T00:00:00.000Z","authors":["alan-ransil","Edwin Fonkwe Fongang","michael-hammersley","Ivan Celanovic","Francis O'Sullivan"],"venue":"IEEE PES Transactive Energy Systems Conference (TESC)","doi":"","publication_types":["conference-paper"],"areas":["distributed-power-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>The future decarbonized power grid will make increasing use of distributed energy resources (DERs) controlled using data collected at an extremely granular level compared to today's coarse bulk power system models. However, the centralized system by which security constrained economic dispatch is implemented at the transmission level cannot be directly applied to a distribution system comprising five orders of magnitude as many nodes engaging in complex scheduling and bidding behavior. Emerging data processing tools such as distributed state estimation algorithms, multiparty computation, blockchains, zero-knowledge proofs and machine learning hold the promise of collecting and processing the necessary data efficiently and securely. In particular, the implementation of transactive energy mirrors the decentralization of the world wide web from a data processing perspective, with similar toolsets required to develop secure, robust algorithmic markets making personalized decisions based on locally relevant datasets. The development of cryptographic tools and data processing infrastructure to build these decentralized markets is advancing rapidly. Meanwhile, capital must be deployed in the  power  system  to  purchase  assets  with  decades-long  lifespans.  In  order  to  balance  the  uncertainty caused by rapid progress with the need to build working systems today, we present  a Computable Multilayered Power System model designed to enable future-proof interoperability. In  our  five-layered  design,  each  layer  performs  one  of  the  essential  functions  needed  to  run  a  power system: State Estimation (SE), Optimization and Dispatch (OD), Transaction (TR), Auditing and  Recording  (AR),  and  Regulation  (RE).  The  specification  of  this  architecture  defines  the  datastructures by which information is exchanged between layers. This ensures that each layer has  access  to  the  data  and  settings  required  to  perform  its  function,  but  ensures  future-proof compatibility by allowing that function to be performed according to any algorithm. Communication between these layers and devices in the field may be performed using existing standards such as  IEEE  2030.5  and  Sunspec  Modbus.  The  five-layer  model  is  amenable  to  hierarchical  implementation, making it compatible with architectures such as laminar coordination frameworks. However, alternative implementations of the layers allow microgrid control, security constrained economic dispatch, building energy management or a sparse implementation such as managing a  subset  of  smart  devices  on  a  distribution  feeder.  Separation  of  Auditing  and  Regulatory  functions  from  other  tasks  allow  novel  concepts  such  as  zero-knowledge  proofs  to  be  readily  implemented,  and  tariff  structures  or  optimization  parameters  easily  changed  in  the  regulatory layer without the need to update other layers manually. Transactions may be billed using existing methods, or the transaction layer may use digital payment channels without affecting other layers. Additionally,  multiple  layers  such  as  Transaction  and  Auditing  may  be  combined  if  performing  these functions together is desired. As new modular tools are developed which offer increasingly efficient  methods  of  coordinating  DERs,  this  functional  separation  of  concerns  will  enable  their  implementation while maintaining compatibility with existing and future systems.</p>\n"},{"slug":"gabizon2019","title":"AuroraLight: Improved prover efficiency and SRS size in a Sonic-like system","date":"2019-05-29T00:00:00.000Z","authors":["ariel-gabizon"],"venue":"","doi":"","publication_types":["report"],"areas":["cryptography"],"abstract":"","url_pdf":"","url_source":"https://eprint.iacr.org/2019/601","html":"<p>Using ideas from the recent Aurora zk-STARK of Ben-Sasson et al. [BCR + 19], we present a zk-SNARK with a universal and updatable SRS similar to the recent construction of Maller et al. [MBKM19], called Sonic. Compared to Sonic, our construction achieves significantly better prover run time (less than half) and smaller SRS size (one sixth). However, we only achieve amortized succinct verification time for batches of proofs, either when the proofs are generated in parallel or in [MBKM19]'s helper setting, and our proofs are longer than those of [MBKM19] (but still contain a constant number of field and group elements).</p>\n"},{"slug":"ransil2018c","title":"Microgrids","date":"2018-12-21T00:00:00.000Z","authors":["alan-ransil"],"venue":"","doi":"","publication_types":["report"],"areas":["distributed-power-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Microgrids are local installations typically connecting one or multiple generation sources with some set of loads. They range in size, from tiny off-grid solar home systems (SHSs) to power infrastructure spanning a university campus or military base. Many are grid connected, enabling owners to consume inexpensive electricity from the larger Generation, Transmission, Distribution and Retail (GTDR) power system while providing redundancy in the case of outage. Many such systems also allow local generation sources to sell power into the GTDR system. Microgrids offer their owners control over their own electrical destiny in exchange for the cost of installing and maintaining parallel electrical infrastructure. They are deeply connected to the proliferation of distributed energy resources (DERs), as they offer DER owners the ability to optimize energy use in order to monetize distributed assets. As DERs continue to become cheaper, along with improvements in the interoperability of microgrid components, the extra cost associated with microgrids should fall. If this coincides with more expensive or less reliable centralized power, the value proposition of a microgrid is likely to appeal to an ever-increasing circle of users. In such a future, the power system may transform from today’s centralized GTDR model into a decentralized network of local microgrids.</p>\n"},{"slug":"fisch2018","title":"Scaling proof-of-replication for Filecoin mining","date":"2018-10-15T00:00:00.000Z","authors":["ben-fisch","joseph-bonneau","nicola-greco","juan-benet"],"venue":"","doi":"","publication_types":["report"],"areas":["cryptography","distributed-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>A proof-of-replication (PoRep) is a proof system that a server can use to demonstrate to a network in a publicly verifiable way that it is dedicating unique resources to storing one or more replicas of a data file. While it is not possible for PoReps to guarantee cryptographically that the prover's storage format is redundant, PoReps do guarantee that: (a) The prover must be using as much space to produce the proof as replicas it claims to store (it is a proof of space) (b) The prover can retrieve a committed data file (it is a proof of retrievability) (c) The prover can use the space to store this file without any overhead In this sense a PoRep is a useful proof of space. It is uniquely suited to replace proof-of-work in Nakamoto consensus as a Sybil resistance mechanism, while simultaneously incen-tivizing and subsidizing the cost of file storage. Technical report This is a short technical report on our constructions. A more detailed paper is forthcoming with information about our prototype implementation of PoReps.</p>\n"},{"slug":"hammersley2018b","title":"Smart grid pilot projects","date":"2018-10-15T00:00:00.000Z","authors":["michael-hammersley"],"venue":"","doi":"","publication_types":["report"],"areas":["distributed-power-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>There are thousands of smart grid pilot projects all around the world, having begun largely in the\nearly 2000s. With the introduction of blockchain, and with the grid becoming more unpredictable\nand decentralized, several use cases are becoming apparent for blockchain. This report points\nto work that has already been done on Smart Grids -- particularly in the United States and\nEurope -- as well as to several blockchain projects underway. The space is quickly becoming\nsaturated, with over 120 blockchain companies as of mid 2018.</p>\n"},{"slug":"ransil2018b","title":"Price signals and demand-side management in the electric distribution and retail system","date":"2018-09-27T00:00:00.000Z","authors":["alan-ransil"],"venue":"","doi":"","publication_types":["report"],"areas":["distributed-power-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>This report focuses on power distribution and retail — the ‘last few miles’ of electricity delivery — because this portion of the power grid in particular must be transformed if we are to decarbonize our energy system. Compared to transmission networks, today’s distribution system is less sophisticated and less well monitored. However, it is the distribution system that will ultimately need to mediate the transition to a cleaner, decentralized energy future. Innovation towards a smarter and more flexible distribution system will thus be central to our efforts.</p>\n"},{"slug":"ransil2018a","title":"Energy pricing","date":"2018-08-23T00:00:00.000Z","authors":["alan-ransil"],"venue":"","doi":"","publication_types":["report"],"areas":["distributed-power-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>This first report focuses on the mechanisms by which electricity is priced in today’s\npower markets. Existing energy markets govern the infrastructure that any widely-used\ntrading protocol must interface with in the short and medium terms. They also suggest\nthe operational requirements that a protocol must satisfy in the long-term, if it is to\neventually replace existing systems or become a ubiquitous platform upon which future\nwholesale markets are built.</p>\n"},{"slug":"fisch2018a","title":"PoReps: Proofs of space on useful data","date":"2018-07-14T00:00:00.000Z","authors":["ben-fisch"],"venue":"","doi":"","publication_types":["report"],"areas":["cryptography","distributed-systems"],"abstract":"","url_pdf":"","url_source":"https://eprint.iacr.org/2018/678","html":"<p>A proof-of-replication (PoRep) is an interactive proof system in which a prover defends a publicly verifiable claim that it is dedicating unique resources to storing one or more retrievable replicas of a data file. In this sense a PoRep is both a proof of space (PoS) and a proof of retrievability (PoR). This paper is a foundational study of PoReps, exploring both their capabilities and their limitations. While PoReps may unconditionally demonstrate possession of data, they fundamentally cannot guarantee that the data is stored redundantly. Furthermore, as PoReps are proofs of space, they must rely either on rational time/space tradeoffs or timing bounds on the online prover's runtime. We introduce a rational security notion for PoReps called epsilon-rational replication based on the notion of an epsilon-Nash equilibrium, which captures the property that a server does not gain any significant advantage by storing its data in any other (non-redundant) format. We apply our definitions to formally analyze two recently proposed PoRep constructions based on verifiable delay functions and depth robust graphs.</p>\n"},{"slug":"benet2017","title":"Proof of replication","date":"2017-07-27T00:00:00.000Z","authors":["juan-benet","david-dalrymple","nicola-greco"],"venue":"","doi":"","publication_types":["report"],"areas":["cryptography","distributed-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>We introduce Proof-of-Replication (PoRep), a new kind of Proof-of-Storage, that can be used to prove that some data D has been replicated to its own uniquely dedicated physical storage. Enforcing unique physical copies enables a verifier to check that a prover is not deduplicating multiple copies of D into the same storage space. This construction is particularly useful in Cloud Computing and Decentralized Storage Networks, which must be transparently verifiable, resistant to Sybil attacks, and unfriendly to outsourcing. This work (a) reviews Proofs-of-Storage and motivates use cases; (b) defines the novel Proofs-of-Replication, which can be publicly verifiable, transparent, authenticated, and time-bounded ; (c) shows how to chain Proofs-of-Replication to establish useful Proofs-of-Spacetime. Work in Progress. This is a work in progress Technical Report from Protocol Labs. Active research is under way, and new versions of this paper will appear.</p>\n"},{"slug":"protocollabs2017","title":"Power fault tolerance","date":"2017-07-27T00:00:00.000Z","authors":["Protocol Labs"],"venue":"","doi":"","publication_types":["report"],"areas":["cryptography","distributed-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Byzantine Fault Tolerance (BFT) accounts for faults as the number of faulty nodes and is thus cumbersome to apply to many modern decentralized systems. We introduce the Power Fault Tolerance (PFT) model, which reframes BFT in terms of participants' influence over the outcome of a protocol, instead of the number of nodes. In PFT, n is the total power, and f is the fraction of power controlled by faulty or adversarial participants. This work: (a) provides a formal definition and properties for PFT; (b) generalizes Byzantine Consensus (BC) protocols of different classes (permissioned, permissionless, and federated) into a single class of Power Consensus (PC); (c) explores new directions for PC protocols, particularly for blockchains, and protocols that can detect and make progress during catastrophic network partitions.</p>\n"},{"slug":"protocollabs2017a","title":"Filecoin: A decentralized storage network","date":"2017-07-19T00:00:00.000Z","authors":["Protocol Labs"],"venue":"","doi":"","publication_types":["report"],"areas":["cryptography","distributed-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>The internet is in the middle of a revolution: centralized proprietary services are being replaced with decentralized open ones; trusted parties replaced with verifiable computation; brittle location addresses replaced with resilient content addresses; inefficient monolithic services replaced with peer-to-peer algo-rithmic markets. Bitcoin, Ethereum, and other blockchain networks have proven the utility of decentralized transaction ledgers. These public ledgers process sophisticated smart contract applications and transact crypto-assets worth tens of billions of dollars. These systems are the first instances of internet-wide Open Services, where participants form a decentralized network providing useful services for pay, with no central management or trusted parties. IPFS has proven the utility of content-addressing by decentralizing the web itself, serving billions of files used across a global peer-to-peer network. It liberates data from silos, survives network partitions, works offline, routes around censorship, and gives permanence to digital information. Filecoin is a decentralized storage network that turns cloud storage into an algorithmic market. The market runs on a blockchain with a native protocol token (also called \"Filecoin\"), which miners earn by providing storage to clients. Conversely, clients spend Filecoin hiring miners to store or distribute data. As with Bitcoin, Filecoin miners compete to mine blocks with sizable rewards, but Filecoin mining power is proportional to active storage, which directly provides a useful service to clients (unlike Bitcoin mining, whose usefulness is limited to maintaining blockchain consensus). This creates a powerful incentive for miners to amass as much storage as they can, and rent it out to clients. The protocol weaves these amassed resources into a self-healing storage network that anybody in the world can rely on. The network achieves robustness by replicating and dispersing content, while automatically detecting and repairing replica failures. Clients can select replication parameters to protect against different threat models. The protocol's cloud storage network also provides security, as content is encrypted end-to-end at the client, while storage providers do not have access to decryption keys. Filecoin works as an incentive layer on top of IPFS [1], which can provide storage infrastructure for any data. It is especially useful for decentralizing data, building and running distributed applications, and implementing smart contracts. This work: (a) Introduces the Filecoin Network, gives an overview of the protocol, and walks through several components in detail. (b) Formalizes decentralized storage network (DSN) schemes and their properties, then constructs File-coin as a DSN. (c) Introduces a novel class of proof-of-storage schemes called proof-of-replication, which allows proving that any replica of data is stored in physically independent storage. (d) Introduces a novel useful-work consensus based on sequential proofs-of-replication and storage as a measure of power. (e) Formalizes verifiable markets and constructs two markets, a Storage Market and a Retrieval Market, which govern how data is written to and read from Filecoin, respectively. (f) Discusses use cases, connections to other systems, and how to use the protocol.</p>\n"},{"slug":"dias2016","title":"Distributed web applications with IPFS","date":"2016-05-25T00:00:00.000Z","authors":["david-dias","juan-benet"],"venue":"16th International Conference on Web Engineering (ICWE)","doi":"10.1007/978-3-319-38791-8_60","publication_types":["tutorial"],"areas":["distributed-systems"],"abstract":"","url_pdf":"","url_source":"https://link.springer.com/chapter/10.1007%2F978-3-319-38791-8_60","html":"<p>The contents of this document describe the tutorial session delivered at ICWE 2016, focused on Building Distributed Web Applications with IPFS. IPFS, the InterPlanetary File System, is the distributed and permanent Web, a protocol to make the Web faster, more secure and open. The tutorial format focuses in key elements of IPFS and how to use it to build applications.</p>\n"},{"slug":"protocollabs2014","title":"Filecoin: A cryptocurrency operated file storage network","date":"2014-07-15T00:00:00.000Z","authors":["Protocol Labs"],"venue":"","doi":"","publication_types":["report"],"areas":["cryptography","distributed-systems"],"abstract":"","url_pdf":"","url_source":"","html":"<p>Filecoin is a distributed electronic currency similar to Bitcoin. Unlike Bitcoin's computation-only proof-of-work, Filecoin's proof-of-work function includes a proof-of-retrievability component, which requires nodes to prove they store a particular file. The Filecoin network forms an entirely distributed file storage system, whose nodes are incentivized to store as much of the entire network's data as they can.</p>\n"},{"slug":"benet2014","title":"IPFS - Content addressed, versioned, P2P file system","date":"2014-07-14T00:00:00.000Z","authors":["juan-benet"],"venue":"","doi":"","publication_types":["report"],"areas":["distributed-systems"],"abstract":"","url_pdf":"","url_source":"https://arxiv.org/abs/1407.3561","html":"<p>The InterPlanetary File System (IPFS) is a peer-to-peer distributed file system that seeks to connect all computing devices with the same system of files. In some ways, IPFS is similar to the Web, but IPFS could be seen as a single BitTorrent swarm, exchanging objects within one Git repository. In other words, IPFS provides a high through-put content-addressed block storage model, with content-addressed hyper links. This forms a generalized Merkle DAG, a data structure upon which one can build versioned file systems, blockchains, and even a Permanent Web. IPFS combines a distributed hashtable, an incentivized block exchange , and a self-certifying namespace. IPFS has no single point of failure, and nodes do not need to trust each other.</p>\n"}]